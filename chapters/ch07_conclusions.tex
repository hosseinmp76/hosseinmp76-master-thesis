\chapter{نتیجه‌گیری}
در این فصل، ضمن جمع‌بندی نتایج جدید ارائه‌شده در پایان‌نامه یا رساله،
مسائل باز باقی‌مانده و همچنین پیشنهادهایی برای ادامه‌ی کار ارائه می‌شوند.


\section{مسیر پژوهشی پیش‌رو}
پیشنهاهای زیر برای ادامه مسیر پژوهشی ارائه می‌شود:
\begin{enumerate}
	\item 
	همان‌طور که در این پژوهش ایده‌ی مزومدار به 
	\picod
	توسعه داده شد یکی از مسیرهای پژوهشی توسعه این ایده برای گونه‌های دیگر مانند کدگذاری اندیس بسیار منعطف است.
	\item 
	یکی از جالب توجه ترین مقالات این حوزه مقاله
	\cite{datashuf}
	از فرگولی است. فرگولی در این مقاله بیان می‌کند که: یکی از زمینه‌های پژوهشی بسیار امیدوارکننده که اخیرا مورد توجه واقع شده، استفاده از تکنیک‌های کدگذاری برای بهبود کارایی ارتباط در سیستم‌های توزیع شده است.
	\cite{Li2015CodedM, 7841903, 8002642, 8051074}
	
	به طور خاص کدگذاری اندیس برای افزایش بهره وری بازآرایی داده پیشنهاد شده است
	\cite{8002642, 8051074}. 

فرگولی در این مقاله با استفاده از کدگذاری اندیس منعطف به جای کدگذاری اندیس کلاسیک مطرح شده در مقالات بالا نشان می‌دهد که 
\picod
چارچوب کاراتری و سودمندتری برای بازآرایی داده ارائه می‌دهد.

در زمینه محاسبات توزیع شده، بازآرایی داده یک گام اصلی در بازتوزیع داده‌ها بین 
\transf{گره‌}{node}های محاسبه‌گر است. برای مثال در
\lr{MapReduce}
یا
\lr{spark}
که دو ابزار معروف محاسبات توزیع شده هستند، داده‌ها در هنگام محاسبات توزیع شده بازآرایی می‌شوند(از گره‌های 
\transf{نگاشت‌گر}{mapper}
 به گره‌های 
 \transf{کاهنده}{reducer}
 منتقل می‌شوند.) بازآرایی داده در انجام کارهای محاسباتی مختلفی استفاده می‌شود. برای مثال در یادگیری ماشین توزیع شده در مقیاس‌های بزرگ بر روی داده‌های حجیم. در این مثال داده‌های محلی هر گره محاسبه گر در هر گام محاسبه باید با داده دیگر گره‌ها بازآرایی شود تا بتوان مدل قدرتمندتری را آموزش داد.
 \footnote{تفاوت کوچکی بین بازآرایی در محاسبات توزیع شده و یادگیری ماشین وجود دارد که در این جا مورد بحث ما نیست. در اینجا ما منظور ما بازتوزیع داده‌ها بین گره‌های محاسبه گر است.}
 در این مقاله تاکید روی مدل
 \transf{ارباب-کارگر}{master-worker}
 در محاسبات توزیع شده است. یعنی یک گره ارباب وجود دارد که دارای
 $m$
 پیام است و از طریق شبکه به
 $n$
 گره کارگر متصل است. هر گره کارگر داراش
 \transf{کش}{cache}
 است که قابلیت ذخیره
 $s_i$
پیام را به صورت محلی برای آن گره داراست. محاسبات به صورت گام به گام انجام می‌شود. در هر گام گره‌های کارگر بر اساس کش خود محاسباتی را انجام می‌دهند و خروجی محاسبات خود را برای گره ارباب ارسال می‌کنند. گره ارباب با تجمیع این خروجی‌ها یک خروجی نهایی برای سیستم به دست می‌آورد. سپس گره ارباب به بازآرایی داده‌ها با ارسال پیام‌های جدید برای تجدید کش گره‌های کارگر می‌پردازد. کاربرد این مدل محاسبه برای مثال، یادگیری ماشین در 
\transf{مرکزهای داده}{data center}
و یا بازی‌های رایانه‌ای ابرمحور است که در هر گام کاربران ویژگی‌های جدید مانند نقشه جدید بازی را دریافت می‌کنند.

استفاده از 
\icod
می‌تواند همچنان هزینه بر باشد زیرا علاوه بر این‌که این مسئله
\nphard
است در بدترین حالت
$\omega(n)$
ارسال و 
\transf{تقریبا همیشه}{almost surely}
$\theta(\dfrac{n}{\log(n)})$
ارسال برای یک نمونه تصادفی از مسئله مورد نیاز است. در این مقاله فرگولی به این سوال می‌پردازد که آیا استفاده از 
\picod
بهبودی ایجاد می‌کند؟

فرگولی و همکاران طرحی شبه تصادفی بر مبنای چارچوب
\picod
ارائه می‌دهند که توازنی بین هزینه‌ی ارتباطی و هزینه‌ی محاسباتی ایجاد می‌کند. آن‌ها نشان می‌دهند اگر
$n, m, s$
به ترتیب تعداد گره‌های کارگر، تعداد پیام‌ها و اندازه کش گره‌ها باشد و
$\dfrac{ns}{m}$
میانگین تعداد گره‌هایی باشد که یک پیام را در کش خود نگه می‌دارند طرح پیشنهادی تا حدود
$O(\dfrac{ns}{m})$
بهبود نسبت به 
\icod
ایجاد می‌کند. همچنین در آزمایش‌های عددی بر روی مجموعه داده‌های واقعی نشان می‌دهند که در مقایسه با ایده‌‌ی بازآرایی تصادفی بر مبنای کدگذاری اندیس حدود
$\%87$
ارسال‌های کمتری مورد نیاز است در حالی که فقط
$\%2$
هزینه‌ی محاسباتی بدتر می‌شود.

یکی از اصلی ترین زمینه‌های پژوهشی در
\picod
ادامه مسیر پژوهشی این مقاله است.
	
\end{enumerate}